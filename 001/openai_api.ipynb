{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN88HI2epK1feW10bM/8Q2H"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        " - [OpenAI](https://beta.openai.com/)\n",
        " - [python-dotenv](https://pypi.org/project/python-dotenv/)\n",
        "\n",
        "        python -m venv venv\n",
        "        source venv/bin/activate\n",
        "        pip install openai python-dotenv\n",
        "        pip freeze >> requirements.txt\n",
        "\n",
        " - **.env**\n",
        "\n",
        "     - [OpenAI Key](https://beta.openai.com/account/api-keys)\n",
        "\n",
        "            OPENAI_API_KEY="
      ],
      "metadata": {
        "id": "0ga2Uh4We6Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from subprocess import run\n",
        "\n",
        "\n",
        "run([\"pip\", \"install\", \"openai\", \"python-dotenv\"])"
      ],
      "metadata": {
        "id": "7GTgW8uZ0wAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "\n",
        "\n",
        "def all_required_variables_have_been_provided(config, variables):\n",
        "    ok = True\n",
        "    for variable in variables:\n",
        "        if variable not in config or not config[variable]:\n",
        "            ok = False\n",
        "            print(f'{variable} is required')\n",
        "    return ok\n",
        "\n",
        "\n",
        "def create_environment_file(**kwargs):\n",
        "    if not all_required_variables_have_been_provided(kwargs, [\n",
        "        'OPENAI_API_KEY'\n",
        "    ]):\n",
        "        return\n",
        "\n",
        "    with open(path.join('.', '.env'), 'w') as env_file:\n",
        "        for key, value in kwargs.items():\n",
        "            env_file.write(f'{key}={value}')\n",
        "\n",
        "\n",
        "create_environment_file(OPENAI_API_KEY='')"
      ],
      "metadata": {
        "id": "elMRtVCZpZOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from os import getenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "print(getenv('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "c2LqAAeb1dyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Models](https://beta.openai.com/docs/models)\n",
        "\n",
        " - [GPT-3](https://beta.openai.com/docs/models/gpt-3): understand and generate natural language.\n",
        "     - text-davinci-003\n",
        "     - text-curie-001\n",
        "     - text-babbage-001\n",
        "     - text-ada-001\n",
        " - [Codex](https://beta.openai.com/docs/models/codex): understand and generate code, including translating natural language to code.\n",
        "     - code-davinci-002\n",
        "     - code-cushman-001\n",
        " - [Moderation](https://beta.openai.com/docs/guides/moderation): can detect whether text may be sensitive or unsafe"
      ],
      "metadata": {
        "id": "BSVJSTyZ4SFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = getenv('OPENAI_API_KEY')\n",
        "\n",
        "def completion_config(model, prompt, **kwargs):\n",
        "    config = {\n",
        "        'model': model,\n",
        "        'prompt': prompt\n",
        "    }\n",
        "\n",
        "    return {**config, **kwargs}\n",
        "\n",
        "\n",
        "def get_text_from_response(response):\n",
        "        return response['choices'][0]['text']"
      ],
      "metadata": {
        "id": "1n0hc9eSQ6ZF"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Text classification](https://monkeylearn.com/text-classification/)\n",
        "\n",
        "Is a machine learning technique that assigns a set of predefined\n",
        "categories to open-ended text. Text classifiers can be used to organize, structure, and categorize documents, medical studies \n",
        "and files.\n",
        "\n",
        "Text classification is one of the fundamental tasks in natural \n",
        "language processing with broad applications such as sentiment \n",
        "analysis, topic labeling, spam detection, and intent detection."
      ],
      "metadata": {
        "id": "pBm68LtADVWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_text_classification(prompt, **kwargs):\n",
        "    config = completion_config(\n",
        "        'text-davinci-003',\n",
        "        prompt,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "    return openai.Completion.create(**config)\n",
        "\n",
        "\n",
        "def build_prompt_for_this_tweet(tweet):\n",
        "    return f\"\"\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "\n",
        "def build_prompt_for_this_tweets(tweets):\n",
        "    parsed_tweets = ''\n",
        "\n",
        "    for index, tweet in enumerate(tweets):\n",
        "        parsed_tweets += f'{index + 1}. \"{tweet}\"\\n'\n",
        "\n",
        "    return f\"\"\"Classify the sentiment in these tweets:\n",
        "\n",
        "{parsed_tweets}\n",
        "\n",
        "Tweet sentiment ratings:\"\"\""
      ],
      "metadata": {
        "id": "10DOTlJMEzQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = perform_text_classification(build_prompt_for_this_tweet(\n",
        "    \"I loved the new Batman movie!\"\n",
        "),\n",
        "    temperature = 0,\n",
        "    max_tokens = 60,\n",
        "    top_p = 1,\n",
        "    frequency_penalty = 0.5,\n",
        "    presence_penalty = 0\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "DjE5ezm4dQsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = perform_text_classification(build_prompt_for_this_tweets([\n",
        "    \"I can't stand homework\",\n",
        "    \"This sucks. I'm bored üò†\",\n",
        "    \"I can't wait for Halloween!!!\",\n",
        "    \"My cat is adorable ‚ù§Ô∏è‚ù§Ô∏è\",\n",
        "    \"I hate chocolate\"\n",
        "]),\n",
        "    temperature = 0,\n",
        "    max_tokens = 60,\n",
        "    top_p = 1,\n",
        "    frequency_penalty = 0,\n",
        "    presence_penalty = 0\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "h3XVrYdodVeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Text Generation](https://spotintelligence.com/2022/12/19/text-generation-nlp/)\n",
        "\n",
        "Is a subfield of natural language processing (NLP) that deals \n",
        "with generating text automatically. It has a wide range of \n",
        "applications, including machine translation, content creation, \n",
        "and conversational agents."
      ],
      "metadata": {
        "id": "yUh_yyv4g_7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_text_generation(prompt, **kwargs):\n",
        "    config = completion_config(\n",
        "        'text-davinci-003',\n",
        "        prompt,\n",
        "        **{\n",
        "            'temperature': 0.6,\n",
        "            'max_tokens': 150,\n",
        "            'top_p': 1,\n",
        "            'frequency_penalty': 1,\n",
        "            'presence_penalty': 1,\n",
        "            **kwargs\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return openai.Completion.create(**config)"
      ],
      "metadata": {
        "id": "tkilJ8ZAhgvC"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = perform_text_generation(\n",
        "    \"Brainstorm some ideas combining Golang and Network programming:\",\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "wEaH3BPhkUgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Conversational AI](https://www.ibm.com/topics/conversational-ai)\n",
        "\n",
        "Conversational artificial intelligence refers to techonologies, \n",
        "like chatbots or virtual agents, which users can talk to. They \n",
        "use large volumes of data, machine learning, and natural \n",
        "language processing to help imitate human interactions, \n",
        "recognizing speech and text inputs and translating their meanings\n",
        "across various languages."
      ],
      "metadata": {
        "id": "yLpVvuD6pT2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_conversation(prompt, **kwargs):\n",
        "    config = completion_config(\n",
        "        'text-davinci-003',\n",
        "        prompt,\n",
        "        **{\n",
        "            'temperature': 0.9,\n",
        "            'max_tokens': 150,\n",
        "            'top_p': 1,\n",
        "            'frequency_penalty': 0,\n",
        "            'presence_penalty': 0.6,\n",
        "            'stop': [' Human:', ' AI:'],\n",
        "            **kwargs\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return openai.Completion.create(**config)\n",
        "\n",
        "\n",
        "def run_jarvis(message):\n",
        "    jarvis_config = f\"\"\"The following is a conversation with an AI assistant \\\n",
        "called Jarvis. The assistant is helpful, creative and clever.\n",
        "\n",
        "Human: {message}\n",
        "AI:\"\"\"\n",
        "\n",
        "    return perform_conversation(jarvis_config)"
      ],
      "metadata": {
        "id": "tS_rJKjnqkXK"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jarvis_chat():\n",
        "    print(\"To exit type 'Bye'\")\n",
        "\n",
        "    while (message := input('Human: ')) != 'Bye':\n",
        "        response = run_jarvis(message.strip())\n",
        "        print(f'Jarvis:{get_text_from_response(response)}')\n",
        "\n",
        "\n",
        "jarvis_chat()"
      ],
      "metadata": {
        "id": "Kv0Ptza6u8sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Transformation"
      ],
      "metadata": {
        "id": "3x16B0l25Hle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_transformation(prompt, **kwargs):\n",
        "    config = completion_config(\n",
        "        'text-davinci-003',\n",
        "        prompt,\n",
        "        **kwargs\n",
        "    )\n",
        "\n",
        "    return openai.Completion.create(**config)"
      ],
      "metadata": {
        "id": "OQy-etLy5GTM"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Translation"
      ],
      "metadata": {
        "id": "Z-SzQ5MADTXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_the_text_to(text, list_of_languages):\n",
        "    languages = ''\n",
        "    for index, language in enumerate(list_of_languages):\n",
        "        languages += f'{index + 1}. {language} '\n",
        "\n",
        "    prompt = f\"\"\"Translate this into {languages.strip()}:\n",
        "\n",
        "{text}\n",
        "\n",
        "1.\"\"\"\n",
        "\n",
        "    response = perform_transformation(prompt, **{\n",
        "        'temperature': 0.3,\n",
        "        'max_tokens': 100,\n",
        "        'top_p': 1,\n",
        "        'frequency_penalty': 0,\n",
        "        'presence_penalty': 0,\n",
        "    })\n",
        "\n",
        "    prompt += get_text_from_response(response)\n",
        "\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "7Mz9U_YWDQIO"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_the_text_to(\n",
        "    'What rooms do you have available?',\n",
        "    ['french', 'spanish', 'japanese']\n",
        ")"
      ],
      "metadata": {
        "id": "amD8urei_QxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Conversion"
      ],
      "metadata": {
        "id": "utxyC1ftDYvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_emoji(text):\n",
        "    prompt = f\"\"\"Represent this phrase with emojis.\n",
        "\n",
        "{text}:\"\"\"\n",
        "\n",
        "    response = perform_transformation(prompt, **{\n",
        "        'temperature': 0.8,\n",
        "        'max_tokens': 60,\n",
        "        'top_p': 1,\n",
        "        'frequency_penalty': 0,\n",
        "        'presence_penalty': 0,\n",
        "    })\n",
        "\n",
        "    prompt += get_text_from_response(response)\n",
        "\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "Q37m5GR5CkMF"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_emoji('Alan Turing, father of computer science')"
      ],
      "metadata": {
        "id": "V1vDOwpzCmSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization"
      ],
      "metadata": {
        "id": "nrItDDQqDjJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_to(level, text):\n",
        "    prompt = f\"\"\"Summarize this for a {level} student:\n",
        "\n",
        "{text}\"\"\"\n",
        "\n",
        "    response = perform_transformation(prompt, **{\n",
        "        'temperature': 0.7,\n",
        "        'max_tokens': 256,\n",
        "        'top_p': 1,\n",
        "        'frequency_penalty': 0,\n",
        "        'presence_penalty': 0,\n",
        "    })\n",
        "\n",
        "    prompt += '\\n\\n' + get_text_from_response(response)\n",
        "\n",
        "    print(prompt)"
      ],
      "metadata": {
        "id": "gQ4CbuLUDmuB"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_to('second-grade',\n",
        "    \"\"\"Computability is the ability to solve a problem in an effective manner.\n",
        "It is a key topic of the field of computability theory within mathematical\n",
        "logic and the theory of computation within computer science. The computability\n",
        "of a problem is closely linked to the existence of an algorithm to solve the problem.\n",
        "\n",
        "The most widely studied models of computability are the Turing-computable and\n",
        "Œº-recursive functions, and the lambda calculus, all of which have computationally\n",
        "equivalent power. Other forms of computability are studied as well: computability\n",
        "notions weaker than Turing machines are studied in automata theory, while\n",
        "computability notions stronger than Turing machines are studied in the field of\n",
        "hypercomputation.\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "poK0y-yTGFyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Completion"
      ],
      "metadata": {
        "id": "2gemF5-1GeJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_this_text(text):\n",
        "    response = openai.Completion.create(**{\n",
        "        'model': 'text-davinci-001',\n",
        "        'prompt': text,\n",
        "        'temperature': 0.29,\n",
        "        'max_tokens': 64,\n",
        "        'top_p': 1,\n",
        "        'frequency_penalty': 0,\n",
        "        'presence_penalty': 0,\n",
        "    })\n",
        "\n",
        "    print(text + get_text_from_response(response))"
      ],
      "metadata": {
        "id": "f7D4TxRtGhLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_this_text('Here all suspicion needs')"
      ],
      "metadata": {
        "id": "aKKCqmtVJCKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_this_code(code):\n",
        "    response = perform_transformation(code, **{\n",
        "        'temperature': 0.7,\n",
        "        'max_tokens': 64,\n",
        "        'top_p': 1,\n",
        "        'frequency_penalty': 0,\n",
        "        'presence_penalty': 0,\n",
        "    })\n",
        "\n",
        "    print(code + get_text_from_response(response))"
      ],
      "metadata": {
        "id": "IqtG3JDvJLyA"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_this_code(\n",
        "    \"\"\"struct Entry {\n",
        "    void* key;\n",
        "    void* value\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "KWPh1mrBJd7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Factual responses"
      ],
      "metadata": {
        "id": "jHU2VWDVLB5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_this_question(question):\n",
        "    prompt = f'Q: {question}\\nA:'\n",
        "\n",
        "    response = perform_transformation(prompt, **{\n",
        "        'temperature': 0,\n",
        "        'max_tokens': 64,\n",
        "        'top_p': 1,\n",
        "        'frequency_penalty': 0,\n",
        "        'presence_penalty': 0,\n",
        "        'stop': ['\\n\\n']\n",
        "    })\n",
        "\n",
        "    print(f'Q: {question}\\n\\nA:{get_text_from_response(response)}')"
      ],
      "metadata": {
        "id": "j_YqFUufLEwR"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_this_question('Who is Donald Knuth?')"
      ],
      "metadata": {
        "id": "PCE-NgYyLZoQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}